# kaggle5dgenai -

# 5-Day Gen AI Intensive Course with Google 


# Day 1 
1. Complete the Intro Unit ‚Äì ‚ÄúFoundational Large Language Models & Text Generation‚Äù, which is:
- [Optional] Listen to the summary podcast episode for this unit (created by NotebookLM).
- Read the ‚ÄúFoundational Large Language Models & Text Generation‚Äù whitepaper.

2. Complete Unit 1 ‚Äì ‚ÄúPrompt Engineering‚Äù, which is:
- [Optional] Listen to the summary podcast episode for this unit (created by NotebookLM).
- Read the ‚ÄúPrompt Engineering‚Äù whitepaper.
- Complete this code lab on Kaggle where you‚Äôll learn prompting fundamentals. Make sure you phone verify your account before starting, it's necessary for the code labs.

üí°What You‚Äôll Learn <br>
Today you‚Äôll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You‚Äôll also get trained in the art of prompt engineering for optimal LLM interaction. <br>
The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts.<br>


# Day 2 

Complete Unit 2: ‚ÄúEmbeddings and Vector Stores/Databases‚Äù, which is:
- [Optional] Listen to the summary podcast episode (https://youtube.com/watch?v=1CC39K76Nqs) for this unit (created by NotebookLM, https://notebooklm.google.com/).
- Read the ‚ÄúEmbeddings and Vector Stores/Databases‚Äù whitepaper (https://kaggle.com/whitepaper-embeddings-and-vector-stores).
- Complete these code labs on Kaggle:
- Build a RAG question-answering system over custom documents - https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag
- Explore text similarity with embeddings - https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores
- Build a neural classification network with Keras using embeddings - https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras

What You‚Äôll Learn <br>
Today you will learn about the conceptual underpinning of embeddings and vector databases and how they can be used to bring live or specialist data into your LLM application. You‚Äôll also explore their geometrical powers for classifying and comparing textual data. 

 Reminders and Announcements <br>
-Here is the recording (https://www.youtube.com/watch?v=kpRyiJUUFxY) from this morning‚Äôs livestream. We apologize for the live technical issues today! Fortunately our recording did not have the same errors.
-The 2nd livestream is tomorrow with Paige Bailey (https://x.com/DynamicWebPaige) and special guests: Omid Fatemieh, Jinhyuk Lee, Alan Li, Iftekhar Naim, Anant Nawalgaria, Yan Qiao, and Xiaoqi Ren.
-Unfortunately, to ensure a fix to our livestream issues, we need to push back our broadcast time. We'll send another email with updated livestream info soon.
-Be sure to ask all your questions about the podcast, readings, and code lab in the ‚Å†5dgai-q-and-a channel on Discord. You'll get Kaggle swag if your question is chosen for discussion during the livestream!

# Day #3 Assignments

Complete Unit 3: ‚ÄúGenerative AI Agents‚Äù, which is: <br>
- [Optional] Listen to the summary podcast episode (https://youtu.be/H4gZd4BCrDQ) for this unit (created by NotebookLM).
- Read the ‚ÄúGenerative AI Agents‚Äù whitepaper (https://www.kaggle.com/whitepaper-agents).
 Complete these code labs on Kaggle:<br>
- Talk to a database with function calling - https://www.kaggle.com/code/markishere/day-3-function-calling-with-the-gemini-api
- Build an agentic ordering system in LangGraph - https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph/

What You‚Äôll Learn<br>

Learn to build sophisticated AI agents by understanding their core components and the iterative development process.
The code labs cover how to connect LLMs to existing systems and to the real world. Learn about function calling by giving SQL tools to a chatbot, and learn how to build a LangGraph agent that takes orders in a caf√©.

Reminders and Announcements

Here is the recording from Day 2‚Äôs  livestream - https://www.youtube.com/live/86GZC56rQCc?si=trAoT7PVtYC5LQ7B
The next livestream is tomorrow at 2pm PST/ 5pm EST/ 10pm UTC. Livestream guests: Alan Blount, Wes Dyer, Steven Johnson, Patrick Marlow, Anant Nawalgaria, and Julia Wiesinger - https://www.youtube.com/watch?v=HQUtMWoTAD4&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es&index=3Livestream
Find a complete list of scheduled livestreams and past recordings here - https://www.youtube.com/playlist?list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es
Be sure to ask all your questions about the podcast, readings, and code lab in the ‚Å†5dgai-q-and-a channel.
Additionally, we‚Äôve added 2 new channels on Discord to enhance discussion:
‚Å†5dgai-question-forum is a discord forum (a special type of channel) where you can create specific threads, which will help finding answers easier in the future.
‚Å†5dgai-course-content is a discord channel for deeper discussion of course content only (excluding technical troubleshooting questions)


# Day 4 
Complete Unit 4: ‚ÄúDomain-Specific LLMs‚Äù, which is:
- ‚û°Ô∏è  [Optional] Listen to the summary podcast episode (https://youtu.be/b1a4ZOQ8XdI) for this unit (created by NotebookLM).
- ‚û°Ô∏è  Read the ‚ÄúSolving Domain-Specific Problems Using LLMs‚Äù whitepaper - https://www.kaggle.com/whitepaper-solving-domains-specific-problems-using-llms 
- ‚û°Ô∏è  Complete these code labs on Kaggle:
[Optional] Use Google Search data in generation. (Note: Grounding with Google Search has been released as a limited launch and is not available in all locations. The EEA, UK, and CH regions will be supported at a later date)
- - https://www.kaggle.com/code/markishere/day-4-google-search-grounding
- Tune a Gemini model for a custom task - https://www.kaggle.com/code/markishere/day-4-fine-tuning-a-custom-model

üí°What You‚Äôll Learn

In today‚Äôs reading, you‚Äôll delve into the creation and application of specialized LLMs like SecLM and MedLM/Med-PaLM, with insights from the researchers who built them.

In the code labs you will learn how to add real world data to a model beyond its knowledge cut-off by grounding with Google Search.  You will also learn how to fine-tune a custom Gemini model using your own labeled data to solve custom tasks.

# Day 5 

Complete Unit 5: ‚ÄúMLOps for Generative AI‚Äù, which is:
- ‚û°Ô∏è [Optional] Listen to the summary podcast episode (https://youtu.be/k9S6IhiUUj4) for this unit (created by NotebookLM, https://notebooklm.google/).
- ‚û°Ô∏è Read the ‚ÄúMLOps for Generative AI‚Äù whitepaper - https://www.kaggle.com/whitepaper-operationalizing-generative-ai-on-vertex-ai-using-mlops
- ‚û°Ô∏è No code lab for today! We will do a code walkthrough and live demo of goo.gle/e2e-gen-ai-app-starter-pack (https://goo.gle/e2e-gen-ai-app-starter-pack), a resource created for making MLOps for Gen AI easier and accelerating the path to production. Please go through the repository in advance.

üí°What You‚Äôll Learn

Discover how to adapt MLOps practices for Generative AI and leverage Vertex AI's tools for foundation models and generative AI applications.

üìã Reminders and Announcements

Here is the recording from Day 4‚Äôs  livestream - https://www.youtube.com/watch?v=odvuLMJWUSU&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es&index=4
5th and final livestream is tomorrow at 2pm PST/ 5pm EST/ 10pm UTC hosted by Paige Bailey (https://x.com/DynamicWebPaige) with special guests: Advait Bopardikar, Sokratis Kartakis, Gabriela Hernandez Larios, Veer Muchandi, Anant Nawalgaria, Elia Secchi, and  Olivia Wiles.
Be sure to ask all your questions about the podcast, readings, and code lab on Discord.
